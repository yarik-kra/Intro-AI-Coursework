{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN - TRAFFIC SIGNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to classify traffic signs using a convolutional neural network (CNN). The dataset contains labelled images of traffic signs, each corresponding to a specific class. Labels are loaded from a CSV file, which maps image identifiers to their class names, ensuring easy association between the images and their respective categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ClassId                          Name\n",
      "0         0           Speed limit (5km/h)\n",
      "1         1          Speed limit (15km/h)\n",
      "2         2          Speed limit (30km/h)\n",
      "3         3          Speed limit (40km/h)\n",
      "4         4          Speed limit (50km/h)\n",
      "5         5          Speed limit (60km/h)\n",
      "6         6          Speed limit (70km/h)\n",
      "7         7          speed limit (80km/h)\n",
      "8         8      Dont Go straight or left\n",
      "9         9     Dont Go straight or Right\n",
      "10       10              Dont Go straight\n",
      "11       11                  Dont Go Left\n",
      "12       12         Dont Go Left or Right\n",
      "13       13                 Dont Go Right\n",
      "14       14       Dont overtake from Left\n",
      "15       15                      No Uturn\n",
      "16       16                        No Car\n",
      "17       17                       No horn\n",
      "18       18          Speed limit (40km/h)\n",
      "19       19          Speed limit (50km/h)\n",
      "20       20          Go straight or right\n",
      "21       21                   Go straight\n",
      "22       22                       Go Left\n",
      "23       23              Go Left or right\n",
      "24       24                      Go Right\n",
      "25       25                     keep Left\n",
      "26       26                    keep Right\n",
      "27       27          Roundabout mandatory\n",
      "28       28            watch out for cars\n",
      "29       29                          Horn\n",
      "30       30             Bicycles crossing\n",
      "31       31                         Uturn\n",
      "32       32                  Road Divider\n",
      "33       33               Traffic signals\n",
      "34       34                  Danger Ahead\n",
      "35       35                Zebra Crossing\n",
      "36       36             Bicycles crossing\n",
      "37       37             Children crossing\n",
      "38       38   Dangerous curve to the left\n",
      "39       39  Dangerous curve to the right\n",
      "40       40                      Unknown1\n",
      "41       41                      Unknown2\n",
      "42       42                      Unknown3\n",
      "43       43          Go right or straight\n",
      "44       44           Go left or straight\n",
      "45       45                      Unknown4\n",
      "46       46                  ZigZag Curve\n",
      "47       47                Train Crossing\n",
      "48       48            Under Construction\n",
      "49       49                      Unknown5\n",
      "50       50                        Fences\n",
      "51       51       Heavy Vehicle Accidents\n",
      "52       52                      Unknown6\n",
      "53       53                      Give Way\n",
      "54       54                   No stopping\n",
      "55       55                      No entry\n",
      "56       56                      Unknown7\n",
      "57       57                      Unknown8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/wx0kw6d17ml1bkwwfxpdjs0c0000gn/T/ipykernel_23944/1860504946.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "file_path = \"/Users/ibhaankudalkar/Downloads/archive/labels.csv\"\n",
    "\n",
    "filename_read = os.path.join(file_path, \"/Users/ibhaankudalkar/Downloads/archive/labels.csv\")\n",
    "df = pd.read_csv(filename_read)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the pytorch libraries, I proceed with the preprocessing of images by resizing it to 32X32 pixels for uniformity across the dataset. Then I transform each image to a tensor and normalize it from scale -1 to 1 which drastically improves the training by ensuring the input data has mean of 0 and a standard deviation of 1.\n",
    "\n",
    "I load the DATA image dataset with each folder representing a class and the name as a label and I preprocess it for loading.\n",
    "\n",
    "the dataset is then split into training-validation-test sets using random as it preserves the dataset sizes. The training set is split 70% of the data (optimizing the model’s weights). The validation set is split 15% (model\"s performance during traing). The test set is split 15% (tunes model’s generalization ability).\n",
    "For maximum efficiency of memory usage I have set the batch size to 32 while loading the sets.\n",
    "\n",
    "For better understanding of the image dataset I plot it on first 3 images with their class labels. The class labels are displayed as titles to provide context for each image which makes the  visualization step check the correctness of the data loading and transformation process.\n",
    "\n",
    "The visualization of images prepares for the training process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 58\n",
      "Train size: 2919\n",
      "Validation size: 625\n",
      "Test size: 626\n",
      "4170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.94509804..0.52156866].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.9607843..0.41960788].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.8901961..0.54509807].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNN Implementation in pytorch \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  \n",
    "import torch.optim \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# transformation \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='/Users/ibhaankudalkar/Downloads/archive/traffic_Data/DATA', transform=transform)\n",
    "num_classes = len(dataset.classes)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# train test split\n",
    "train_size = int(0.7 * len(dataset)) # 70\n",
    "val_size = int(0.15 * len(dataset)) # 15\n",
    "test_size = len(dataset) - train_size - val_size # 15\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "print(\"Train size:\", train_size)\n",
    "print(\"Validation size:\", val_size)\n",
    "print(\"Test size:\", test_size)\n",
    "print(train_size + val_size + test_size)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Sample of images \n",
    "def samples(images, labels, class_names):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(len(images)):  \n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0).numpy())  \n",
    "        plt.title(f\"Class: {class_names[labels[i]]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# batch of data\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# first 3 images\n",
    "samples(images[:3], labels[:3], dataset.classes)\n",
    "\n",
    "# print(f\"Image shape: {sample_images[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I define the CNN Model class which inherits the pytorch module, making it structural and modular for training.\n",
    "I define three convolutional layers:\n",
    "The first layer processes the 3-channel RGB input with 32 filters of size 3x3.\n",
    "The next two layers increase the number of filters to 64 and 128, capturing more complex patterns at each stage.\n",
    "Padding of 1 ensures the output spatial dimensions remain consistent after convolution.\n",
    "The max pooling layer is 2X2 to downsize the feature maps by half. Next, I flatten the maps to 128*4*4 for a dense mapping with 512 neurons.\n",
    "Dropout layers are added to reduce overfitting by half.\n",
    "\n",
    "In the Forward Pass, each layer is passed by a ReLu activation function compared to others as it outputs 0 for negative inputs and speeds the training in dense networks.\n",
    "I have also added view for flattening it from 2D maps to 1D vector.\n",
    "The CNN constructor adjusts the output layer to match the dataset’s classes, ensuring compatibility regardless of the number of categories.\n",
    "The  Cross Entropy loss funtion helps to convert the c2 layer high probabilities to classes as it combines the log-softmax and negative log into a single log function.\n",
    "Lastly, I have used Adam Optimizer as it reduces oscillation during gradient descent and gives a faster convergence rates with a learning rate of 0.001 for stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN MODEL CLASS\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, number_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.c1 = nn.Linear(128 * 4 * 4, 512)  \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.c2 = nn.Linear(512, number_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4) \n",
    "        x = F.relu(self.c1(x))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        x = self.c2(x)\n",
    "        return x\n",
    "\n",
    "# model intialization and optimization\n",
    "model = CNN(number_classes=num_classes)\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Training Model, each epoch completes one round over training and validation.\n",
    "The images and labels are put into batches as it optimizes the memory and are passed through the model to give prediction for each image.\n",
    "the loss function tracks the difference in predictions and labels so I compute the gradient for the loss and the parameters are optimized.\n",
    "The running loss is used to calculate the average training loss later on.\n",
    "I specifically used zero_grad as my optimizer as it provides with each batch gradient computation and gradients from previous batches do not interfere with the current batch.\n",
    "\n",
    "In the Validation step, I switch off the gradient descent with no_grad reducing memory usage. The validation dataset loaded in batches is passed through the model to generate predictions and for each batch the loss is calculated.\n",
    "i did use torch.max to normalize the scores for each class.\n",
    "Based on our predictions with the labels I calculate the accuracy.\n",
    "\n",
    "Lastly, I print the metrics for each epoch and the call the training model.\n",
    "\n",
    "Changing the epoch from 10 to 8 made validation accuracy stabilize at 98.40% after just the first epoch, showing that the model learns the key patterns quickly.\n",
    "Training loss is extremely low, indicating that the model fits the training data almost perfectly.\n",
    "the risk of overfitting is minimal with stable performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Train Loss: 0.0026, Validation Loss: 0.1364, Validation Accuracy: 98.40%\n",
      "Epoch 2/8, Train Loss: 0.0010, Validation Loss: 0.1459, Validation Accuracy: 98.40%\n",
      "Epoch 3/8, Train Loss: 0.0003, Validation Loss: 0.1512, Validation Accuracy: 98.40%\n",
      "Epoch 4/8, Train Loss: 0.0002, Validation Loss: 0.1544, Validation Accuracy: 98.40%\n",
      "Epoch 5/8, Train Loss: 0.0002, Validation Loss: 0.1569, Validation Accuracy: 98.40%\n",
      "Epoch 6/8, Train Loss: 0.0001, Validation Loss: 0.1588, Validation Accuracy: 98.40%\n",
      "Epoch 7/8, Train Loss: 0.0001, Validation Loss: 0.1609, Validation Accuracy: 98.40%\n",
      "Epoch 8/8, Train Loss: 0.0001, Validation Loss: 0.1625, Validation Accuracy: 98.40%\n"
     ]
    }
   ],
   "source": [
    "# train model for each epoch\n",
    "def train_model(model, train_loader, val_loader,criteria, optimizer, epochs=8):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criteria(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                outputs = model(images)\n",
    "                loss = criteria(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "              f\"Train Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "              f\"Validation Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "              f\"Validation Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criteria, optimizer, epochs=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I seperately evaluate the trained model and set it to evaluation mode giving a accuracy score as a percentage for the model.\n",
    "Lastly, I call the model on test_model.\n",
    "\n",
    "An accuracy between 96-99% indicated the test samples are demonstrating good generalization to raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 97.44%\n"
     ]
    }
   ],
   "source": [
    "# Testing and Evaluation\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Accuracy Score: {100 * correct / total:.2f}%\")\n",
    "\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "torch.save(model, 'model.pth')\n",
    "print('Saved trained model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
