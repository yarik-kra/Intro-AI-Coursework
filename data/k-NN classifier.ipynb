{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Traffic Sign Classification Using KNN\n",
    "\n",
    "I created a K-Nearest Neighbours (KNN) model for this project in order to group traffic signs into the right groups.  In order to improve the model's effectiveness and efficiency, the goal was to find out how well KNN handled image data while tackling problems like class imbalance and dimensionality reduction. Here is an overview of the actions I took, along with an explanation of my results, observations, and possible areas for improvement."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Paths to Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = '/Users/fatima..../Documents/GitHub/Intro-AI-Coursework/data/traffic_Data/DATA'\n",
    "test_path = '/Users/fatima..../Documents/GitHub/Intro-AI-Coursework/data/traffic_Data/TEST'\n",
    "labels_path = '/Users/fatima..../Documents/GitHub/Intro-AI-Coursework/data/labels.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading and Processing Data\n",
    "In order to map each class ID to a traffic sign, I first loaded the class labels from a CSV file. I examined the distribution of photographs in each class to have a better understanding of my dataset:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = pd.read_csv(labels_path)\n",
    "class_image_counts = {}\n",
    "for class_id in range(58):\n",
    "    directory = os.path.join(data_path, str(class_id))\n",
    "    if os.path.exists(directory):\n",
    "        class_image_counts[class_id] = len(os.listdir(directory))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_image_counts.keys(), class_image_counts.values())\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images in Each Class')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With some classes having more than 200 photos and others having fewer than 10, the bar chart showed an obvious class imbalance. The overall accuracy might decrease as a result of the model choosing classes with more examples because of this imbalance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Handling Class Imbalance\n",
    "I duplicated images for classes with fewer than 10 samples and limited the number of samples per class to 100 in order to fix the imbalance in the class.  The goal of this modification was to achieve the greatest possible balance in the distribution of the data.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images, class_ids = [], []\n",
    "max_samples = 100\n",
    "min_samples = 10\n",
    "for class_id in range(58):\n",
    "    directory = os.path.join(data_path, str(class_id))\n",
    "    if os.path.exists(directory):\n",
    "        img_files = os.listdir(directory)\n",
    "        img_count = 0\n",
    "        for img_file in img_files:\n",
    "            if img_count < max_samples:\n",
    "                img_path = os.path.join(directory, img_file)\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.resize(image, (32, 32))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                images.append(image.flatten())\n",
    "                class_ids.append(class_id)\n",
    "                img_count += 1\n",
    "        if img_count < min_samples:\n",
    "            for i in range(min_samples - img_count):\n",
    "                images.append(image.flatten())\n",
    "                class_ids.append(class_id)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scaling Features and Reducing Dimensionality\n",
    "Once the dataset had been loaded and balanced, I adjusted the photos to have an equal variation and a zero mean. This is crucial for KNN since it depends on distance calculations, which might be affected by irregular feature scales.\n",
    "\n",
    "I then used Principal Component Analysis (PCA) to lower the number of variables.  I chose 350 key variables since they represented a majority of the variation, according to the cumulative variance plot."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X = np.array(images)\n",
    "y = np.array(class_ids)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=350)  # Adjust components based on cumulative variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "pca_test = PCA().fit(X_scaled)\n",
    "plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.title('PCA Cumulative Variance')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, I noticed that the cumulative variance increases rapidly.  This indicates that a significant amount of the dataset's information is captured by the first few components. In other words, the first components capture the most significant features (or patterns) in the data.\n",
    "\n",
    "The curve levels off after about 350 components, indicates that adding more components beyond this point does not significantly increase the explained variance. We have now recorded almost all the significant variance, as the curve has essentially stopped.\n",
    "\n",
    "I chose 350 components because they make up more than 95% of the datasetâ€™s variance. This suggests that I'm keeping most of the key information while drastically reducing the data's dimensionality, which is necessary to increase the model's efficiency without sacrificing important information.\n",
    "\n",
    "The KNN model works more quickly and effectively when the dataset is reduced to 350 dimensions, Without losing\n",
    "reliability, this method should improve the model's performance.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Splitting and KNN Model Training\n",
    "Almost all the dataset was used for training, while the rest was used for validation. After that, I changed the number of neighbours (k) to seven and used distance-based weighting to give closer neighbours a greater impact when defining and training a KNN model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split Data into Training and Validation Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and Train the KNN Model\n",
    "k = 7\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='minkowski', p=2)\n",
    "knn.fit(X_train, y_train);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I used Euclidean distance (Minkowski distance with p=2), which is a common choice for continuous data, and k = 7 was used to balance the model's bias and variance.\n",
    "Accuracy can be increased, particularly in datasets with uneven classes, by ensuring that close to neighbours had greater impact through distance weighting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assessing the Model\n",
    "In order to determine if the model was overfitting or underfitting, I evaluated its accuracy on both the training and validation sets:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_acc = knn.score(X_train, y_train)\n",
    "val_acc = knn.score(X_val, y_val)\n",
    "print(f\"Training Accuracy: {train_acc:.3f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. This is usual with KNN on data that is imbalanced, that slightly lower validation accuracy points to some over fitting, but the high training accuracy shows the model fits the training data well.\n",
    "\n",
    "2. Validation Accuracy: 0.874 - although there is an obvious decrease in comparing with the training accuracy, the model fits to unseen data very well, with an accuracy of 87.4% on the validation data set.  This is to be expected as training accuracy is usually higher than validation accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final Testing and Model Performance\n",
    "I handled the test set in the same way using the same scaling and PCA changes in order to evaluate the model's performance on unseen data. I created a confusion matrix, a classification report, and an accuracy calculation after sorting each prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert Test Data to Numpy Arrays\n",
    "X_test = np.array(images)\n",
    "y_test = np.array(class_ids)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "y_pred = knn.predict(X_test_pca)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test Accuracy: 0.97 - 97% accuracy on the test set indicates that the model is very good at generalising to data that has never been seen before, which is an excellent result.  The model is accurately predicting new traffic sign images, as shown in the high test accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
